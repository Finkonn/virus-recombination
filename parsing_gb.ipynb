{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "import re\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get records from .gb file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'FMDV_all_records.gb'\n",
    "genbank_records = SeqIO.parse(file_path, 'gb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create empty lists for storing necessary information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hosts = []\n",
    "collection_dates = []\n",
    "countries = []\n",
    "cities = []\n",
    "isolation_sources = []\n",
    "isolates = []\n",
    "strains = []\n",
    "serotypes = []\n",
    "record_ids = []\n",
    "references = []\n",
    "number_of_records = 0\n",
    "CDS_count = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The function checks if the qualifier is a list and returns the appropriate value.\n",
    "If the qualifier is a list, its first element is returned.\n",
    "If the qualifier is not a list, it is returned as is.\n",
    "If the qualifier is not found by the key, the string 'Unknown' is returned. \n",
    "\"\"\"\n",
    "def parse_qualifier(qualifier, key):\n",
    "    value = qualifier.get(key, 'Unknown')\n",
    "    return value if not isinstance(value, list) else value[0]\n",
    "\n",
    "def merge_values(values):\n",
    "    #Merges multiple values into one by prioritizing non-'Unknown' values.\n",
    "    for value in values:\n",
    "        if value != 'Unknown':\n",
    "            return value\n",
    "    return 'Unknown'\n",
    "\n",
    "# The function applies parse_qualifier to the necessary qualifiers.\n",
    "def extract_data_from_record(record):\n",
    "    features = record.features\n",
    "    source_feature_list = [feature for feature in features if feature.type == 'source']\n",
    "\n",
    "    # Dictionary to store merged values for each qualifier\n",
    "    merged_values = {\n",
    "        'host': [],\n",
    "        'collection_date': [],\n",
    "        'country': [],\n",
    "        'isolation_source': [],\n",
    "        'isolate': [],\n",
    "        'strain': [],\n",
    "        'serotype': []\n",
    "    }\n",
    "\n",
    "    # Iterate through 'source' features\n",
    "    for source_feature in source_feature_list:\n",
    "        qual_dict = source_feature.qualifiers\n",
    "\n",
    "        # Iterate through qualifiers and merge values\n",
    "        for key in merged_values.keys():\n",
    "            merged_values[key].append(parse_qualifier(qual_dict, key))\n",
    "\n",
    "    # Append merged values to respective lists\n",
    "    hosts.append(merge_values(merged_values['host']))\n",
    "    collection_dates.append(merge_values(merged_values['collection_date']))\n",
    "    countries.append(merge_values(merged_values['country']))\n",
    "    isolation_sources.append(merge_values(merged_values['isolation_source']))\n",
    "    isolates.append(merge_values(merged_values['isolate']))\n",
    "    strains.append(merge_values(merged_values['strain']))\n",
    "    serotypes.append(merge_values(merged_values['serotype']))\n",
    "\n",
    "    # Extract references\n",
    "    for reference in record.annotations[\"references\"]:\n",
    "        references.append(reference.title)\n",
    "        break\n",
    "\n",
    "    # Extract record ids    \n",
    "    record_ids.append(record.name)\n",
    "\n",
    "# Execute the function for each record in the .gb file.\n",
    "for record in genbank_records:\n",
    "    extract_data_from_record(record)\n",
    "    CDS_count += sum(1 for feature in record.features if feature.type == 'CDS')\n",
    "    number_of_records += 1\n",
    "\n",
    "print(\"Number of records:\", number_of_records)\n",
    "print(\"Number of CDS:\", CDS_count)\n",
    "print(\"Hosts:\", hosts[:5])\n",
    "print(\"Collection Dates:\", collection_dates[:5])\n",
    "print(\"Countries:\", countries[:5])\n",
    "#print(\"Cities:\", cities[:5])\n",
    "print(\"Isolation Sources:\", isolation_sources[:5])\n",
    "print(\"Isolates:\", isolates[:5])\n",
    "print(\"Strains:\", strains[:5])\n",
    "print(\"Serotypes:\", serotypes[:5])\n",
    "print(\"Record IDs:\", record_ids[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for reading map.csv files\n",
    "def read_csv(file_name):\n",
    "    with open(file_name) as csvfile:\n",
    "        reader = csv.DictReader(csvfile,\n",
    "                                delimiter=\",\", \n",
    "                                fieldnames=[\"base\", \"new\"])\n",
    "        result = {}\n",
    "        \n",
    "        for row in reader:\n",
    "            base_value = row[\"base\"].strip()\n",
    "            new_value = row[\"new\"].strip().rstrip(';')\n",
    "            result[base_value] = new_value\n",
    "        csvfile.close()\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function maps values from a list to values in a CSV file.\n",
    "def map_qualifiers(qualifier, csv_file):\n",
    "    data_dict = read_csv(csv_file)\n",
    "    feature_map_comp = [(re.compile(key), value) for key, value in data_dict.items()]\n",
    "    mapped_values = []\n",
    "    for name in qualifier:\n",
    "        for regex, new_name in feature_map_comp:\n",
    "            match = regex.search(name)\n",
    "            if match:\n",
    "                mapped_values.append(new_name)\n",
    "                break\n",
    "        else:\n",
    "            mapped_values.append(name)\n",
    "    return mapped_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping hosts\n",
    "hosts_mapped = map_qualifiers(hosts, 'Maps/host_map.csv')\n",
    "\n",
    "# Mapping countries\n",
    "countries_mapped = map_qualifiers(countries, 'Maps/country_map.csv')\n",
    "\n",
    "# Converting all dates to years\n",
    "collection_years = ['Unknown' if date == 'Unknown' else (date[-4:] if date[-4:].isdigit() else date[:4]) for date in collection_dates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function prints unique values and their count in the list\n",
    "def print_sorted_counts(items):\n",
    "    count_dict = {}\n",
    "    for item in items:    \n",
    "        count_dict[item] = count_dict.get(item, 0) + 1\n",
    "    \n",
    "    for key, value in sorted(count_dict.items(), key=lambda x: x[1], reverse=True):\n",
    "        print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below you can output the values ​​of qualifiers with frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Values of the host qualifier\n",
    "print(\"Counts for hosts:\")\n",
    "print_sorted_counts(hosts_mapped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Values of the country qualifier\n",
    "print(\"Counts for countries:\")\n",
    "print_sorted_counts(countries_mapped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Values for collection_date qualifier\n",
    "print(\"Counts for collection_dates:\")\n",
    "print_sorted_counts(collection_years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Values for isolation_source qualifier\n",
    "print(\"Counts for isolation_sources:\")\n",
    "print_sorted_counts(isolation_sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Values for isolate qualifier\n",
    "print(\"Counts for isolates:\")\n",
    "print_sorted_counts(isolates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Values for strain qualifier\n",
    "print(\"Counts for strains:\")\n",
    "print_sorted_counts(strains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Values for serotype qualifier\n",
    "print(\"Counts for serotypes:\")\n",
    "print_sorted_counts(serotypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save qualifier values to a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'GenBankAccession': record_ids,\n",
    "    'Country': countries_mapped,\n",
    "    'Host': hosts_mapped,\n",
    "    'CollectionDate': collection_years,\n",
    "    'Serotype': serotypes,\n",
    "    'Strain': strains,\n",
    "    'Isolate': isolates,\n",
    "    'IsolationSource': isolation_sources\n",
    "})\n",
    "df.to_csv('qualifiers_table.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read file with sources to remove\n",
    "def read_exclusion_criteria(file_name):\n",
    "    with open(file_name, 'r') as file:\n",
    "        exclusion_criteria = [line.strip() for line in file]\n",
    "    return exclusion_criteria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function extracts CDS sequences and creates a FASTA file with headers in the format >GenbankAC/country/host/year/serotype.\n",
    "\n",
    "For this purpose, mapped lists are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_fasta_from_genbank(genbank_records, hosts, collection_dates, countries, serotypes, record_ids, isolation_exclusion_file, reference_exclusion_file, output_file):\n",
    "    isolation_exclusion_criteria = read_exclusion_criteria(isolation_exclusion_file)\n",
    "    reference_exclusion_criteria = read_exclusion_criteria(reference_exclusion_file)\n",
    "    with open(output_file, 'w') as fasta_file:\n",
    "        for i, record in enumerate(genbank_records):  \n",
    "\n",
    "            isolation_source = isolation_sources[i]\n",
    "            reference = references[i]\n",
    "\n",
    "            # Check if the isolation source matches any exclusion criteria\n",
    "            if any(re.search(criteria, isolation_source) for criteria in isolation_exclusion_criteria):\n",
    "                continue  # Skip this record\n",
    "            \n",
    "            # Check if the reference matches any exclusion criteria\n",
    "            if any(re.search(criteria, reference) for criteria in reference_exclusion_criteria):\n",
    "                continue  # Skip this record\n",
    "            \n",
    "            # Constructing the header\n",
    "            header = f\">{record_ids[i].replace(' ', '-')}/{countries[i].replace(' ', '-')}/{hosts[i].replace(' ', '-')}/{collection_dates[i].replace(' ', '-')}/{serotypes[i].replace(' ', '-')}\"\n",
    "            fasta_file.write(header + '\\n')\n",
    "\n",
    "            cds_list = []\n",
    "            # Getting the coordinates of the coding sequence/sequences\n",
    "            for feature in record.features:\n",
    "                if feature.type == 'CDS':\n",
    "                    # Check if product qualifier is 'polyprotein'\n",
    "                    if 'product' in feature.qualifiers:\n",
    "                        product_value = feature.qualifiers['product'][0]\n",
    "                        pattern = r'(?i)(polyprotein|poylprotein|polyprotein precursor|polypeptide)'\n",
    "                        if re.match(pattern, product_value): \n",
    "                        \n",
    "                            cds_start = feature.location.start.position\n",
    "                            cds_end = feature.location.end.position\n",
    "                            \n",
    "                            cds_sequence = record.seq[cds_start:cds_end]\n",
    "                            cds_list.append(str(cds_sequence))\n",
    "                            full_cds = ''.join(cds_list)\n",
    "\n",
    "            # Writing the sequence, moving to a new line every 70 characters\n",
    "            for i in range(0, len(full_cds), 70):\n",
    "                fasta_file.write(str(full_cds[i:i+70]) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genbank_records = SeqIO.parse(file_path, 'gb')\n",
    "write_fasta_from_genbank(genbank_records, hosts_mapped, collection_years, countries_mapped, serotypes, record_ids, 'isolation_sources_to_remove.txt', 'references_to_remove.txt', 'extracted_CDS_full.fasta')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
